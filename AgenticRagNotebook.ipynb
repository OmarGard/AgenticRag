{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load secret keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_secrets():\n",
    "    with open('secrets.json') as secrets_file:\n",
    "        return json.load(secrets_file)\n",
    "secrets = get_secrets()\n",
    "os.environ[\"LANGSMITH_API_KEY\"]  = secrets.get(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = secrets.get(\"GOOGLE_API_KEY\")\n",
    "os.environ[\"GOOGLE_CSE_ID\"] = secrets.get(\"GOOGLE_CSE_ID\")\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-up LLama3.2 model locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_llm = \"llama3.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating local index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving docs from web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    \"https://www.planetary.org/space-missions/curiosity\",\n",
    "    \"https://www.rmg.co.uk/stories/topics/mars-nasa-rover-perseverance-facts-dates\"\n",
    "]\n",
    "\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=250, chunk_overlap=0\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform text to embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding Model\n",
    "oembed = OllamaEmbeddings(base_url=\"http://localhost:11434\", model=\"nomic-embed-text\")\n",
    "\n",
    "# Add to vectorDB\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=oembed,\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intelligent Document Retrieval and Grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Retrieval Grader\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 'yes'}\n"
     ]
    }
   ],
   "source": [
    "# LLM\n",
    "llm = ChatOllama(model=local_llm, format=\"json\", temperature=0)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing relevance \n",
    "    of a retrieved document to a user question. If the document contains keywords related to the user question, \n",
    "    grade it as relevant. It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \\n\n",
    "    Provide the binary score as a JSON with a single key 'score' and no premable or explanation.\n",
    "     <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Here is the retrieved document: \\n\\n {document} \\n\\n\n",
    "    Here is the user question: {question} \\n <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "    \"\"\",\n",
    "    input_variables=[\"question\", \"document\"],\n",
    ")\n",
    "\n",
    "retrieval_grader = prompt | llm | JsonOutputParser()\n",
    "question = \"perseverance mission rover\"\n",
    "docs = retriever.invoke(question)\n",
    "doc_txt = docs[1].page_content\n",
    "print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Perseverance rover is a NASA mission that aims to search for signs of past and present life on Mars. It was launched on July 30, 2020, and landed on February 18, 2021, in the Jezero Crater. The rover's four key objectives are:\n",
      "\n",
      "1. Searching for signs of habitable conditions on Mars in the ancient past\n",
      "2. Searching for signs of past microbial life itself\n",
      "3. Testing out new technologies to aid future human missions to Mars\n",
      "4. Producing oxygen on the Martian surface\n",
      "\n",
      "The rover is equipped with state-of-the-art instruments and will perform numerous scientific experiments during its mission, which is intended to last at least two years.\n"
     ]
    }
   ],
   "source": [
    "### Generate\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Prompt\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are an assistant for question-answering tasks. \n",
    "    Use only and EXCLUSIVELY the following pieces of retrieved context to answer the question. \n",
    "    If you don't know the answer or if the provided context is not enough to answer the question, just say that you don't know. \n",
    "    Keep the answer concise and coherent. <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Question: {question} \n",
    "    Context: {context} \n",
    "    Answer: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"question\", \"document\"],\n",
    ")\n",
    "\n",
    "llm = ChatOllama(model=local_llm, temperature=0)\n",
    "\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# Chain\n",
    "rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Run\n",
    "question = \"What can you tell me about Perseverance mission to Mars?\"\n",
    "docs = retriever.invoke(question)\n",
    "generation = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting and correcting hallucinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 'yes'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Hallucination Grader\n",
    "\n",
    "# LLM\n",
    "llm = ChatOllama(model=local_llm, format=\"json\", temperature=0)\n",
    "\n",
    "# Prompt\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\" <|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing whether \n",
    "    an answer is grounded in / supported by a set of facts. Give a binary 'yes' or 'no' score to indicate \n",
    "    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \n",
    "    single key 'score' and no preamble or explanation. <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Here are the facts:\n",
    "    \\n ------- \\n\n",
    "    {documents} \n",
    "    \\n ------- \\n\n",
    "    Here is the answer: {generation}  <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"generation\", \"documents\"],\n",
    ")\n",
    "\n",
    "hallucination_grader = prompt | llm | JsonOutputParser()\n",
    "hallucination_grader.invoke({\"documents\": docs, \"generation\": generation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 'yes'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Answer Grader\n",
    "\n",
    "# LLM\n",
    "llm = ChatOllama(model=local_llm, format=\"json\", temperature=0)\n",
    "\n",
    "# Prompt\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing whether an \n",
    "    answer is useful to resolve a question. Give a binary score 'yes' or 'no' to indicate whether the answer is \n",
    "    useful to resolve a question. Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\n",
    "     <|eot_id|><|start_header_id|>user<|end_header_id|> Here is the answer:\n",
    "    \\n ------- \\n\n",
    "    {generation} \n",
    "    \\n ------- \\n\n",
    "    Here is the question: {question} <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"generation\", \"question\"],\n",
    ")\n",
    "\n",
    "answer_grader = prompt | llm | JsonOutputParser()\n",
    "answer_grader.invoke({\"question\": question, \"generation\": generation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datasource': 'web_search'}\n"
     ]
    }
   ],
   "source": [
    "### Router\n",
    "\n",
    "# LLM\n",
    "llm = ChatOllama(model=local_llm, format=\"json\", temperature=0)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are an expert at routing a \n",
    "    user question to a vectorstore or web search. Use the vectorstore for questions only and exclusively related to Curiosity or Perseverance missions to Mars.\n",
    "    Otherwise, use web_search. \n",
    "    Note: Ignore any punctuation such as question marks or exclamation points when determining the appropriate datasource.\n",
    "    You do not need to be stringent with the keywords in the question related to these topics. \n",
    "    Otherwise, use web-search. Give a binary choice 'web_search' or 'vectorstore' based on the question. \n",
    "    Return the a JSON with a single key 'datasource' and no premable or explanation. \n",
    "    \n",
    "    Question to route: {question} <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"question\"],\n",
    ")\n",
    "\n",
    "question_router = prompt | llm | JsonOutputParser()\n",
    "question = \"What can you tell me about Obama?\"\n",
    "\n",
    "print(question_router.invoke({\"question\": question}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fallback to Google Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Barack Obama - Wikipedia',\n",
       "  'link': 'https://en.wikipedia.org/wiki/Barack_Obama',\n",
       "  'snippet': 'A member of the Democratic Party, he was the first African-American president. Obama previously served as a U.S. senator representing Illinois from 2005 to 2008\\xa0...'},\n",
       " {'title': 'President Barack Obama | Barack Obama Presidential Library',\n",
       "  'link': 'https://www.obamalibrary.gov/obamas/president-barack-obama',\n",
       "  'snippet': 'Obama was elected the first African-American president of the Harvard Law Review, prior to graduating magna cum laude in 1991. He returned to Chicago in 1992\\xa0...'},\n",
       " {'title': 'Barack Obama (@barackobama) â€¢ Instagram photos and videos',\n",
       "  'link': 'https://www.instagram.com/barackobama/?hl=en',\n",
       "  'snippet': 'As this year comes to a close, I want to wish all of you a safe and joyful holiday season.'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_community import GoogleSearchAPIWrapper\n",
    "from langchain_core.tools import Tool\n",
    "\n",
    "search = GoogleSearchAPIWrapper(k=3)\n",
    "def search_results(query):\n",
    "    return search.results(query, num_results=3)\n",
    "\n",
    "web_search_tool = Tool(\n",
    "    name=\"google_search\",\n",
    "    description=\"Search Google for recent results.\",\n",
    "    func=search_results\n",
    ")\n",
    "question = \"Who is Obama?\"\n",
    "# search.results(\"Who is Obama?\", num_results=3)\n",
    "results = web_search_tool.invoke({\"query\": question})\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Graph Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from typing import List\n",
    "from langchain_core.documents import Document\n",
    "from pprint import pprint\n",
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "### State\n",
    "MAX_ATTEMPTS = 2\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "    \n",
    "    Attributes:\n",
    "        question: question\n",
    "        generation: LLM generation\n",
    "        web_search: whether to add search\n",
    "        documents: list of documents\n",
    "        attempts: number of generation attempts\n",
    "    \"\"\"\n",
    "    question: str\n",
    "    generation: str\n",
    "    web_search: str\n",
    "    documents: List[str]\n",
    "    attempts: int\n",
    "\n",
    "### Nodes\n",
    "\n",
    "def retrieve(state):\n",
    "    print(\"---RETRIEVE---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = retriever.invoke(question)\n",
    "    return {\"documents\": documents, \"question\": question, \"attempts\": state.get(\"attempts\", 0)}\n",
    "\n",
    "def generate(state):\n",
    "    print(\"---GENERATE---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    attempts = state.get(\"attempts\", 0) + 1\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    return {\"documents\": documents, \"question\": question, \"generation\": generation, \"attempts\": attempts}\n",
    "\n",
    "def grade_documents(state):\n",
    "    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    filtered_docs = []\n",
    "    web_search = \"No\"\n",
    "    \n",
    "    for d in documents:\n",
    "        score = retrieval_grader.invoke({\"question\": question, \"document\": d.page_content})\n",
    "        grade = score[\"score\"]\n",
    "        if grade.lower() == \"yes\":\n",
    "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "            web_search = \"Yes\"\n",
    "            continue\n",
    "    \n",
    "    return {\"documents\": filtered_docs, \"question\": question, \"web_search\": web_search, \"attempts\": state.get(\"attempts\", 0)}\n",
    "\n",
    "def web_search(state):\n",
    "    print(\"---WEB SEARCH---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state.get(\"documents\", [])\n",
    "    docs = web_search_tool.invoke({\"query\": question})\n",
    "    web_results = \"\\n\".join([d[\"snippet\"] for d in docs])\n",
    "    web_results = Document(page_content=web_results)\n",
    "    documents.append(web_results)\n",
    "    return {\"documents\": documents, \"question\": question, \"attempts\": state.get(\"attempts\", 0)}\n",
    "\n",
    "def route_question(state):\n",
    "    print(\"---ROUTE QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    source = question_router.invoke({\"question\": question})\n",
    "    print(source[\"datasource\"])\n",
    "    if source[\"datasource\"] == \"web_search\":\n",
    "        return \"websearch\"\n",
    "    return \"vectorstore\"\n",
    "\n",
    "def decide_to_generate(state):\n",
    "    print(\"---ASSESS GRADED DOCUMENTS---\")\n",
    "    if state[\"web_search\"] == \"Yes\":\n",
    "        print(\"---DECISION: INCLUDE WEB SEARCH---\")\n",
    "        return \"websearch\"\n",
    "    print(\"---DECISION: GENERATE---\")\n",
    "    return \"generate\"\n",
    "\n",
    "def grade_generation_v_documents_and_question(state):\n",
    "    print(\"---CHECK HALLUCINATIONS---\")\n",
    "    attempts = state.get(\"attempts\", 0)\n",
    "    if attempts > MAX_ATTEMPTS:\n",
    "        return \"stop\"\n",
    "    \n",
    "    score = hallucination_grader.invoke({\"documents\": state[\"documents\"], \"generation\": state[\"generation\"]})\n",
    "    grade = score[\"score\"]\n",
    "    \n",
    "    if grade == \"yes\":\n",
    "        print(\"---DECISION: GENERATION IS GROUNDED---\")\n",
    "        score = answer_grader.invoke({\"question\": state[\"question\"], \"generation\": state[\"generation\"]})\n",
    "        if score[\"score\"] == \"yes\":\n",
    "            return \"useful\"\n",
    "        return \"not useful\"\n",
    "    return \"not supported\"\n",
    "\n",
    "def stop(state):\n",
    "    return {\"generation\": \"I'm sorry, I was not able to produce an answer\", \"attempts\": state.get(\"attempts\", 0)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x11edf4890>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node(\"websearch\", web_search)  # web search\n",
    "workflow.add_node(\"retrieve\", retrieve)  # retrieve\n",
    "workflow.add_node(\"grade_documents\", grade_documents)  # grade documents\n",
    "workflow.add_node(\"generate\", generate)  # generate\n",
    "workflow.add_node(\"stop\", stop)  # stop\n",
    "\n",
    "# Build graph\n",
    "workflow.set_conditional_entry_point(\n",
    "    route_question,\n",
    "    {\n",
    "        \"websearch\": \"websearch\",\n",
    "        \"vectorstore\": \"retrieve\",\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"websearch\": \"websearch\",\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"websearch\", \"generate\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate\",\n",
    "    grade_generation_v_documents_and_question,\n",
    "    {\n",
    "        \"not supported\": \"generate\",\n",
    "        \"useful\": END,\n",
    "        \"not useful\": \"websearch\",\n",
    "        \"stop\": \"stop\"\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the workflow\n",
    "app = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---ROUTE QUE STION---\n",
      "What can you tell me about Perseverance mission?\n",
      "{'datasource': 'vectorstore'}\n",
      "vectorstore\n",
      "---ROUTE QUESTION TO RAG---\n",
      "---RETRIEVE---\n",
      "'Finished running: retrieve:'\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\n",
      "'Finished running: grade_documents:'\n",
      "---WEB SEARCH---\n",
      "'Finished running: websearch:'\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n",
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "'Finished running: generate:'\n",
      "('The Perseverance rover is a NASA mission designed to search for signs of '\n",
      " 'past and present life on Mars, as well as test technologies to support '\n",
      " 'future human travel to the planet. Its four key objectives are:\\n'\n",
      " '\\n'\n",
      " '1. Searching for signs of past and present life on Mars\\n'\n",
      " '2. Testing out new technologies to aid future human missions to Mars\\n'\n",
      " '3. Collecting core samples of Martian rock and regolith (broken rock and '\n",
      " 'soil) for potential pickup by a future mission\\n'\n",
      " '4. Producing oxygen on the Martian surface with an instrument designed for '\n",
      " 'this purpose.\\n'\n",
      " '\\n'\n",
      " \"The rover is part of NASA's ongoing Mars 2020 missions and is intended to \"\n",
      " 'last at least two years.')\n"
     ]
    }
   ],
   "source": [
    "# Testing the workflow\n",
    "\n",
    "inputs = {\"question\": \"What can you tell me about Perseverance mission?\"}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Finished running: {key}:\")\n",
    "        if key in [\"generate\", \"stop\"]:\n",
    "            pprint(value[\"generation\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---ROUTE QUE STION---\n",
      "What can you tell me about Oportunity mission?\n",
      "{'datasource': 'vectorstore'}\n",
      "vectorstore\n",
      "---ROUTE QUESTION TO RAG---\n",
      "---RETRIEVE---\n",
      "'Finished running: retrieve:'\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\n",
      "'Finished running: grade_documents:'\n",
      "---WEB SEARCH---\n",
      "'Finished running: websearch:'\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n",
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "'Finished running: generate:'\n",
      "(\"I don't know about the Opportunity mission. The provided context doesn't \"\n",
      " 'mention any information about a space mission called \"Opportunity\". However, '\n",
      " 'I can tell you that there was a Mars rover mission called \"Opportunity\" '\n",
      " 'which was launched in 2003 and explored Mars from 2004 to 2018. If this is '\n",
      " 'not the one you are referring to, please provide more context or '\n",
      " 'information.')\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"question\": \"What can you tell me about Oportunity mission?\"}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Finished running: {key}:\")\n",
    "        if key in [\"generate\", \"stop\"]:\n",
    "            pprint(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---ROUTE QUESTION---\n",
      "web_search\n",
      "---WEB SEARCH---\n",
      "'Finished running: websearch:'\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "'Finished running: generate:'\n",
      "(\"I don't know who the first president of the USA was. The provided context \"\n",
      " 'mentions James Madison and James Monroe as presidents, but it does not '\n",
      " 'mention the first president of the USA. It also mentions John Hanson, who is '\n",
      " 'referred to as the \"first full-term President of the United States in '\n",
      " 'Congress Assembled\", but this title is different from being the first '\n",
      " 'president of the USA.')\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "'Finished running: generate:'\n",
      "(\"I don't know who the first president of the USA was. The provided context \"\n",
      " 'mentions James Madison and James Monroe as presidents, but it does not '\n",
      " 'mention the first president of the USA. It also mentions John Hanson, who is '\n",
      " 'referred to as the \"first full-term President of the United States in '\n",
      " 'Congress Assembled\", but this title is different from being the first '\n",
      " 'president of the USA.')\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "'Finished running: generate:'\n",
      "(\"I don't know who the first president of the USA was. The provided context \"\n",
      " 'mentions James Madison and James Monroe as presidents, but it does not '\n",
      " 'mention the first president of the USA. It also mentions John Hanson, who is '\n",
      " 'referred to as the \"first full-term President of the United States in '\n",
      " 'Congress Assembled\", but this title is different from being the first '\n",
      " 'president of the USA.')\n",
      "'Finished running: stop:'\n",
      "\"I'm sorry, I was not able to produce an answer\"\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"question\": \"Who was the first president of the USA?\"}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Finished running: {key}:\")\n",
    "        if key in [\"generate\", \"stop\"]:\n",
    "            pprint(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
